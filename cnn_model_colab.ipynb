{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_model_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKYM_pGyTWXe",
        "colab_type": "code",
        "outputId": "d9297a38-e6a0-4cb0-8d3c-2277b5ceced0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pip install python_speech_features\n",
        "!pip install python-dotenv "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.6/dist-packages (0.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnbYpwQmb9vl",
        "colab_type": "code",
        "outputId": "4d517ab1-b5da-4b41-cc39-ab07609f1532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install keras --upgrade"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcPEqN0nU5yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip list librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnRPrBVPP2lj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f892418d-aca6-4a1d-e509-74743fd9fd45"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from python_speech_features import mfcc\n",
        "import os\n",
        "# import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/cs577- Deep learning/deepMusic/')\n",
        "import utils\n",
        "from sklearn import preprocessing\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "# config = tf.compat.v1.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# sess = tf.compat.v1.Session(config=config)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TUdItkeSTiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "\n",
        "    def __init__(self, list_IDs, labels, loader, audio_dir, batch_size=32, dim=(32, 32, 32), n_channels=1,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.loader = loader\n",
        "        self.audio_dir = audio_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        # print(list_IDs_temp)\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # # Store sample\n",
        "            # signal, rate = self.loader.load(utils.get_audio_path(self.audio_dir, ID))\n",
        "            # sample = signal[:rate]\n",
        "            \n",
        "            # # Shorten the sample to 10 secs\n",
        "            # ran_index = np.random.randint(0, signal.shape[0] - int(rate / 10))\n",
        "            # sample = signal[ran_index:ran_index + int(rate / 10)]\n",
        "            # # print(f'shape of sample -> {sample.shape}')\n",
        "\n",
        "            # normalized_X = preprocessing.normalize(mfcc(sample, rate, numcep=13, nfilt=26, nfft=1103).T)\n",
        "            # temp = np.array(normalized_X)\n",
        "            # rshaped_X = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
        "            # X[i,] = rshaped_X\n",
        "\n",
        "            # Librosa version mel spectrogram\n",
        "            signal, sr = self.loader.load(utils.get_audio_path(self.audio_dir, ID))\n",
        "            signal = signal.astype(float)\n",
        "            # Shorten the sample to 10 secs\n",
        "            ran_index = np.random.randint(0, signal.shape[0] - int(sr / 1))\n",
        "            sample = signal[ran_index:ran_index + int(sr / 1)]\n",
        "            # print(sr)\n",
        "            spect = librosa.feature.melspectrogram(y=sample, sr=sr, n_mels=64,fmax=8000)\n",
        "            \n",
        "            # plt.figure(figsize=(10, 5))\n",
        "            # librosa.display.specshow(spect.T, y_axis='mel', x_axis='time')\n",
        "            # plt.colorbar(format='%+2.0f dB')\n",
        "            # plt.title('Test Melspectogram')\n",
        "            # plt.show()\n",
        "\n",
        "            temp = np.array(spect)\n",
        "            rshaped_X = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
        "            X[i,] = rshaped_X\n",
        "\n",
        "            # X[i,] = np.array(spect)\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels.loc[ID].to_numpy()\n",
        "\n",
        "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2J3kgdVUaaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_mel_spect(loader,audio_dir,ID):\n",
        "    signal, sr = loader.load(utils.get_audio_path(audio_dir, ID))\n",
        "    signal = signal.astype(float)\n",
        "    # Shorten the sample to 10 secs\n",
        "    ran_index = np.random.randint(0, signal.shape[0] - int(sr / 1))\n",
        "    sample = signal[ran_index:ran_index + int(sr / 1)]\n",
        "    spect = librosa.feature.melspectrogram(y=sample, sr=sr, n_mels=64,fmax=8000)\n",
        "    \n",
        "    plt.figure(figsize=(10, 5))\n",
        "    librosa.display.specshow(spect.T, y_axis='mel', x_axis='time')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Test Melspectogram')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp7np9sznbD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "2f8e3c1e-4515-479b-dfaa-f0e2dde04ced"
      },
      "source": [
        "# # Train and Validate\n",
        "ff_loader = utils.FfmpegLoader()\n",
        "\n",
        "# Plot mel spect for audio file with ID 2\n",
        "plot_mel_spect(ff_loader,AUDIO_DIR,2)\n",
        "\n",
        "# METHOD 2 - DATAGENERATOR\n",
        "# Parameters\n",
        "params = {'dim': (64, 87),\n",
        "          'batch_size': 10,\n",
        "          'n_classes': 8,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': True}\n",
        "training_generator = DataGenerator(train.index.values, labels_onehot,ff_loader, AUDIO_DIR, **params)\n",
        "x , y = training_generator.__getitem__(0)\n",
        "print(x.shape)\n",
        "# print(train.loc[ID]['track_genre_top'])\n",
        "print(y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAFNCAYAAABR1JR4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nav8fsl1pwWxEKTwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(10, 64, 87, 1)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNABix_hQG6H",
        "colab_type": "code",
        "outputId": "f5a8052d-c96a-4bc5-e94a-bb7767460479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "\n",
        "# print(keras.__version__)\n",
        "root_folder = \"/content/drive/My Drive/cs577- Deep learning/deepMusic/\"\n",
        "AUDIO_DIR = root_folder + 'fma_small'\n",
        "\n",
        "# Read data\n",
        "tracks = pd.read_csv(root_folder+'fma_metadata/subset_small.csv', index_col=0)\n",
        "print(tracks['set_split'].shape)\n",
        "train = tracks.loc[tracks['set_split'] == 'training']\n",
        "val = tracks.loc[tracks['set_split'] == 'validation']\n",
        "test = tracks.loc[tracks['set_split'] == 'test']\n",
        "print(f'train -> {train.columns}')\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7995,)\n",
            "train -> Index(['album_comments', 'album_date_created', 'album_date_released',\n",
            "       'album_engineer', 'album_favorites', 'album_id', 'album_information',\n",
            "       'album_listens', 'album_producer', 'album_tags', 'album_title',\n",
            "       'album_tracks', 'album_type', 'artist_active_year_begin',\n",
            "       'artist_active_year_end', 'artist_associated_labels', 'artist_bio',\n",
            "       'artist_comments', 'artist_date_created', 'artist_favorites',\n",
            "       'artist_id', 'artist_latitude', 'artist_location', 'artist_longitude',\n",
            "       'artist_members', 'artist_name', 'artist_related_projects',\n",
            "       'artist_tags', 'artist_website', 'artist_wikipedia_page', 'set_split',\n",
            "       'set_subset', 'track_bit_rate', 'track_comments', 'track_composer',\n",
            "       'track_date_created', 'track_date_recorded', 'track_duration',\n",
            "       'track_favorites', 'track_genre_top', 'track_genres',\n",
            "       'track_genres_all', 'track_information', 'track_interest',\n",
            "       'track_language_code', 'track_license', 'track_listens',\n",
            "       'track_lyricist', 'track_number', 'track_publisher', 'track_tags',\n",
            "       'track_title'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwiYWOcZRcxL",
        "colab_type": "code",
        "outputId": "0395d3e7-0c31-40c7-c13c-294a6099c37c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "\n",
        "# Check which genres are present\n",
        "genres = list(LabelEncoder().fit(train['track_genre_top']).classes_)\n",
        "print('Top genres ({}): {}'.format(len(genres), genres))\n",
        "\n",
        "# one hot encode y\n",
        "# labels_onehot = LabelBinarizer().fit_transform(tracks['track_genre_top'])\n",
        "# labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)\n",
        "# print(f'labels_onehot -> {labels_onehot.head()}')\n",
        "\n",
        "labels_onehot = np.asarray(LabelEncoder().fit_transform(tracks['track_genre_top']))\n",
        "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)\n",
        "print(f'labels_onehot -> {labels_onehot.head()}')\n",
        "# print(f'label type {labels_onehot.shape}')\n",
        "\n",
        "# For local training purposes\n",
        "train = train.head(100)\n",
        "val = val.head(100)\n",
        "test = test.head(100)\n",
        "print(f'test.index.values -> {len(test.index.values)}')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top genres (8): ['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Pop', 'Rock']\n",
            "labels_onehot ->           0\n",
            "track_id   \n",
            "2         3\n",
            "5         3\n",
            "10        6\n",
            "140       2\n",
            "141       2\n",
            "test.index.values -> 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVYnJESrR_j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def gen_model():\n",
        "  # Input shape is this because 13->numcep in mfcc function and 9 -> number of frames considered\n",
        "  # input_shape = (13, 9, 1)\n",
        "  input_shape = (64, 87, 1)\n",
        "\n",
        "  # Network Architecture\n",
        "  # tf.keras.backend.clear_session()\n",
        "\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(16, (3, 3), activation='relu',\n",
        "                          strides=(1, 1), padding='same',\n",
        "                          input_shape=input_shape))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                          strides=(1, 1), padding='same',\n",
        "                          ))\n",
        "  model.add(layers.MaxPool2D(2, 2))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(8, activation='softmax'))\n",
        "  model.summary()\n",
        "\n",
        "  # optimizer = optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
        "  optimizer = optimizers.Adam(lr=0.01)\n",
        "  model.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-7MTIuSK-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # Train and Validate\n",
        "ff_loader = utils.FfmpegLoader()\n",
        "\n",
        "# METHOD 2 - DATAGENERATOR\n",
        "# Parameters\n",
        "params = {'dim': (13, 9),\n",
        "          'batch_size': 10,\n",
        "          'n_classes': 8,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': True}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vs1X2R3d_E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_epocs_graph(history_dict):\n",
        "    loss_vals = history_dict['loss']\n",
        "    val_loss_vals = history_dict['val_loss']\n",
        "    epochs = range(1, len(history_dict['acc']) + 1)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss_vals, 'g', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss_vals, 'b', label='Validation Loss')\n",
        "    plt.title(\"Training and validation loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    acc_vals = history_dict['acc']\n",
        "    val_acc_vals = history_dict['val_acc']\n",
        "    plt.plot(epochs, acc_vals, 'g', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc_vals, 'b', label='Validation accuracy')\n",
        "    plt.title(\"Training and validation Accuracy\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    # plt.savefig(\"../doc/graphs/val_loss_acc_epochs_before1_task2.png\")\n",
        "    # plt.savefig(\"../doc/graphs/val_loss_acc_epochs_after1_task2.png\")\n",
        "    plt.show()\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az2xoihAdg-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "97241550-703d-4115-9284-a48349ba9a98"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
        "\n",
        "def _get_available_gpus():\n",
        "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
        "\n",
        "    # Returns\n",
        "        A list of available GPU devices.\n",
        "    \"\"\"\n",
        "    #global _LOCAL_DEVICES\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.__version__ is 2.2.0-rc2\n",
            "tf.keras.__version__ is: 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thaLUsaWSQBb",
        "colab_type": "code",
        "outputId": "27e7d468-ec73-4afc-c85d-4d2c437894d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# cnn\n",
        "# model = gen_model()\n",
        "\n",
        "# CRNN\n",
        "# input_shape = (64,18,1)\n",
        "# model_input = layers.Input(input_shape, name='input')\n",
        "# model = conv_recurrent_model_build(model_input,input_shape)\n",
        "\n",
        "# CNN by mdeff\n",
        "# input_shape = (64,18,1)\n",
        "# model = getMdeff_model(input_shape)\n",
        "\n",
        "# Another trial\n",
        "model = MusicTaggerCNN(weights=None, input_tensor=(64,87,1))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# model.load_weights(\"/content/crnn_net_gru_adam_ours_epoch_40.h5\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(train.index.values, labels_onehot,ff_loader,AUDIO_DIR, **params)\n",
        "validation_generator = DataGenerator(val.index.values, labels_onehot,ff_loader,AUDIO_DIR, **params)\n",
        "test_generator = DataGenerator(test.index.values, labels_onehot,ff_loader,AUDIO_DIR, **params)\n",
        "\n",
        "# Train model on dataset\n",
        "train_val_history = model.fit_generator(generator=training_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    epochs=5,\n",
        "                    # steps_per_epoch = 20,\n",
        "                    use_multiprocessing=True, workers=1)\n",
        "history_dict = train_val_history.history\n",
        "plot_epocs_graph(history_dict=history_dict)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), name=\"conv1\", trainable=False, padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=3, name=\"bn1\", trainable=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"conv2\", trainable=False, padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=3, name=\"bn2\", trainable=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"conv3\", trainable=False, padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=3, name=\"bn3\", trainable=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 64, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "bn_0_freq (BatchNormalizatio (None, 64, 87, 1)         256       \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 64, 87, 32)        320       \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 64, 87, 32)        128       \n",
            "_________________________________________________________________\n",
            "elu_10 (ELU)                 (None, 64, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 32, 21, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 32, 21, 128)       36992     \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 32, 21, 128)       512       \n",
            "_________________________________________________________________\n",
            "elu_11 (ELU)                 (None, 32, 21, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 16, 5, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 16, 5, 128)        147584    \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 16, 5, 128)        512       \n",
            "_________________________________________________________________\n",
            "elu_12 (ELU)                 (None, 16, 5, 128)        0         \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 8, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "Flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 194,504\n",
            "Trainable params: 8,200\n",
            "Non-trainable params: 186,304\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 30s 3s/step - loss: 2.6337 - accuracy: 0.2700 - val_loss: 12925811712.0000 - val_accuracy: 0.1000\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 30s 3s/step - loss: 2.1523 - accuracy: 0.3300 - val_loss: 13544530944.0000 - val_accuracy: 0.1400\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 30s 3s/step - loss: 1.9862 - accuracy: 0.3600 - val_loss: 5631875584.0000 - val_accuracy: 0.1700\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 30s 3s/step - loss: 1.6155 - accuracy: 0.4200 - val_loss: 6628022784.0000 - val_accuracy: 0.2600\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 30s 3s/step - loss: 1.7436 - accuracy: 0.4300 - val_loss: 16245063680.0000 - val_accuracy: 0.1900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8e53ef33e582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                     use_multiprocessing=True, workers=1)\n\u001b[1;32m     21\u001b[0m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplot_epocs_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-f7184c0b5190>\u001b[0m in \u001b[0;36mplot_epocs_graph\u001b[0;34m(history_dict)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF58iBAAM5V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMdeff_model(input_shape):\n",
        "  model = models.Sequential()\n",
        "  # model.add(layers.Reshape((-1, 1), input_shape=input_shape))\n",
        "  # print(model.output_shape)\n",
        "\n",
        "  model.add(layers.Conv1D(128, 512, subsample_length=512,input_shape=input_shape))\n",
        "  # print(model.output_shape)\n",
        "  model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "  model.add(layers.Conv1D(32, 8))\n",
        "  # print(model.output_shape)\n",
        "  model.add(layers.Activation(\"relu\"))\n",
        "  model.add(layers.MaxPooling1D(4))\n",
        "\n",
        "  model.add(layers.Conv1D(32, 8))\n",
        "  # print(model.output_shape)\n",
        "  model.add(layers.Activation(\"relu\"))\n",
        "  model.add(layers.MaxPooling1D(4))\n",
        "\n",
        "  # print(model.output_shape)\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(layers.Flatten())\n",
        "  print(model.output_shape)\n",
        "  model.add(layers.Dense(100))\n",
        "  model.add(layers.Activation(\"relu\"))\n",
        "  # print(model.output_shape)\n",
        "  model.add(layers.Dense(labels_onehot.shape[1]))\n",
        "  model.add(layers.Activation(\"softmax\"))\n",
        "  # print(model.output_shape)\n",
        "\n",
        "  optimizer = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "  #optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4HXlVcG2Lcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 8\n",
        "N_LAYERS = 3\n",
        "FILTER_LENGTH = 5\n",
        "CONV_FILTER_COUNT = 56\n",
        "BATCH_SIZE = 32\n",
        "LSTM_COUNT = 96\n",
        "EPOCH_COUNT = 70\n",
        "NUM_HIDDEN = 64\n",
        "L2_regularization = 0.001\n",
        "\n",
        "\n",
        "def conv_recurrent_model_build(model_input,input_shape):\n",
        "    print('Building model...')\n",
        "    layer = model_input\n",
        "    \n",
        "    ### 3 1D Convolution Layers\n",
        "    for i in range(N_LAYERS):\n",
        "        # give name to the layers\n",
        "        layer = layers.Conv2D(\n",
        "                filters=CONV_FILTER_COUNT,\n",
        "                kernel_size=FILTER_LENGTH,\n",
        "                kernel_regularizer=regularizers.l2(L2_regularization),  # Tried 0.001\n",
        "                name='convolution_' + str(i + 1),\n",
        "                data_format='channels_last',\n",
        "                strides=1, padding='same',\n",
        "                input_shape = input_shape\n",
        "            )(layer)\n",
        "        layer = layers.BatchNormalization(momentum=0.9)(layer)\n",
        "        layer = layers.Activation('relu')(layer)\n",
        "        layer = layers.MaxPooling2D(pool_size=2,padding='same',\n",
        "                data_format='channels_last',)(layer)\n",
        "        layer = layers.Dropout(0.4)(layer)\n",
        "    \n",
        "    # ## LSTM Layer\n",
        "    # layer = layers.LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
        "    # layer = layers.Dropout(0.4)(layer)\n",
        "    \n",
        "    # ## Dense Layer\n",
        "    # layer = layers.Dense(NUM_HIDDEN, kernel_regularizer=regularizers.l2(L2_regularization), name='dense1')(layer)\n",
        "    # layer = layers.Dropout(0.4)(layer)\n",
        "    \n",
        "    # ## Softmax Output\n",
        "    # layer = layers.Dense(num_classes)(layer)\n",
        "    # layer = layers.Activation('softmax', name='output_realtime')(layer)\n",
        "\n",
        "    model_output = layer\n",
        "    model = models.Model(model_input, model_output)\n",
        "    \n",
        "    \n",
        "    opt = optimizers.Adam(lr=0.001)\n",
        "    model.compile(\n",
        "            loss='categorical_crossentropy',\n",
        "            optimizer=opt,\n",
        "            metrics=['acc']\n",
        "        )\n",
        "    \n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJzHcClh11xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Test the network\n",
        "# print(\"Testing network on test set...\")\n",
        "# test_history = model.evaluate_generator(test_generator,use_multiprocessing=True, workers=1)\n",
        "\n",
        "# print(test_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLyu4PhXZOgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "from keras import backend as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.layers import Input, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVRzvz45ZT0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pop_layer(model):\n",
        "    if not model.outputs:\n",
        "        raise Exception('Sequential model cannot be popped: model is empty.')\n",
        "\n",
        "    model.layers.pop()\n",
        "    if not model.layers:\n",
        "        model.outputs = []\n",
        "        model.inbound_nodes = []\n",
        "        model.outbound_nodes = []\n",
        "    else:\n",
        "        model.layers[-1].outbound_nodes = []\n",
        "        model.outputs = [model.layers[-1].output]\n",
        "    model.built = False\n",
        "\n",
        "\n",
        "def MusicTaggerCNN(weights='msd', input_tensor=None):\n",
        "    '''Instantiate the MusicTaggerCNN architecture,\n",
        "    optionally loading weights pre-trained\n",
        "    on Million Song Dataset. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_dim_ordering=\"tf\"` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The dimension ordering\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "    For preparing mel-spectrogram input, see\n",
        "    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
        "    You will need to install [Librosa](http://librosa.github.io/librosa/)\n",
        "    to use it.\n",
        "    # Arguments\n",
        "        weights: one of `None` (random initialization)\n",
        "            or \"msd\" (pre-training on ImageNet).\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        include_top: whether to include the 1 fully-connected\n",
        "            layer (output layer) at the top of the network.\n",
        "            If False, the network outputs 256-dim features.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    '''\n",
        "    if weights not in {'msd', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `msd` '\n",
        "                         '(pre-training on Million Song Dataset).')\n",
        "\n",
        "    input_shape = (64,87,1)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        melgram_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        melgram_input = Input(shape=input_tensor)\n",
        "\n",
        "\n",
        "    channel_axis = 3\n",
        "    freq_axis = 2\n",
        "    time_axis = 1\n",
        "\n",
        "    # Input block\n",
        "    x = BatchNormalization(axis=time_axis, name='bn_0_freq', trainable=False)(melgram_input)\n",
        "\n",
        "    # Conv block 1\n",
        "    x = Convolution2D(32, 3, 3, border_mode='same', name='conv1', trainable=False)(x)\n",
        "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn1', trainable=False)(x)\n",
        "    x = ELU()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 4), name='pool1', trainable=False)(x)\n",
        "\n",
        "    # Conv block 2\n",
        "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv2', trainable=False)(x)\n",
        "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn2', trainable=False)(x)\n",
        "    x = ELU()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 4), name='pool2')(x)\n",
        "\n",
        "    # Conv block 3\n",
        "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv3', trainable=False)(x)\n",
        "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=False)(x)\n",
        "    x = ELU()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 4), name='pool3')(x)\n",
        "\n",
        "    # # Conv block 4\n",
        "    # x = Convolution2D(192, 3, 3, border_mode='same', name='conv4', trainable=False)(x)\n",
        "    # x = BatchNormalization(axis=channel_axis, mode=0, name='bn4', trainable=False)(x)\n",
        "    # x = ELU()(x)\n",
        "    # x = MaxPooling2D(pool_size=(3, 5), name='pool4', trainable=False)(x)\n",
        "\n",
        "    # # Conv block 5\n",
        "    # x = Convolution2D(256, 3, 3, border_mode='same', name='conv5')(x)\n",
        "    # x = BatchNormalization(axis=channel_axis, mode=0, name='bn5')(x)\n",
        "    # x = ELU()(x)\n",
        "    # x = MaxPooling2D(pool_size=(4, 4), name='pool5')(x)\n",
        "\n",
        "    # Output\n",
        "    x = Flatten(name='Flatten_1')(x)\n",
        "\n",
        "    if weights is None:\n",
        "        # Create model\n",
        "        x = Dense(8, activation='softmax', name='output')(x)\n",
        "        model = Model(melgram_input, x)\n",
        "        return model\n",
        "    else:\n",
        "        # Load input\n",
        "        x = Dense(50, activation='sigmoid', name='output')(x)\n",
        "        # if K.image_dim_ordering() == 'tf':\n",
        "        #     raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
        "        #                        \"You can set it at ~/.keras/keras.json\")\n",
        "        # Create model\n",
        "        initial_model = Model(melgram_input, x)\n",
        "        initial_model.load_weights('/content/music_tagger_cnn_weights_tensorflow.h5',\n",
        "                                   by_name=True)\n",
        "\n",
        "        # Eliminate last layer\n",
        "        pop_layer(initial_model)\n",
        "\n",
        "        # Add new Dense layer\n",
        "        last = initial_model.get_layer('Flatten_1')\n",
        "        preds = (Dense(10, activation='sigmoid', name='preds'))(last.output)\n",
        "        model = Model(initial_model.input, preds)\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}