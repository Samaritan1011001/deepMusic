{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_using_generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKYM_pGyTWXe",
        "colab_type": "code",
        "outputId": "89c879a6-53f7-43a6-9d00-dd09a28746ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "!pip install python_speech_features\n",
        "!pip install python-dotenv \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=211f124af37a57ffc8dafb51a4217ab402129f6f76550dcca2836716b29745a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n",
            "Collecting python-dotenv\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/2a/07f87440444fdf2c5870a710b6770d766a1c7df9c827b0c90e807f1fb4c5/python_dotenv-0.13.0-py2.py3-none-any.whl\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnbYpwQmb9vl",
        "colab_type": "code",
        "outputId": "4e56125d-0108-48c2-ec5e-8a5d3ab2c27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install keras --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcPEqN0nU5yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip list librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnRPrBVPP2lj",
        "colab_type": "code",
        "outputId": "23226529-a353-40ac-a539-c04f34805e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from python_speech_features import mfcc\n",
        "import os\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras import activations\n",
        "from keras import backend as K\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/cs577- Deep learning/deepMusic/')\n",
        "import utils\n",
        "from sklearn import preprocessing\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from math import floor\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
        "\n",
        "def _get_available_gpus():\n",
        "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
        "\n",
        "    # Returns\n",
        "        A list of available GPU devices.\n",
        "    \"\"\"\n",
        "    #global _LOCAL_DEVICES\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.__version__ is 2.2.0-rc3\n",
            "tf.keras.__version__ is: 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkycMAkFYqAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Small dataset\n",
        "gen_params = {\n",
        "          'dim': (96,1366),\n",
        "          # 'dim': (96,469),\n",
        "          'batch_size': 10,\n",
        "          'n_classes': 4,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': True}\n",
        "\n",
        "root_folder = '/content/drive/My Drive/cs577- Deep learning/deepMusic/'\n",
        "config = { \n",
        "    'audio_dir' : root_folder + 'fma_small',\n",
        "    'tracks' : root_folder +'fma_metadata/subset_small.csv',\n",
        "    'generator_params': gen_params,\n",
        "    'audio_loader' : utils.FfmpegLoader()\n",
        "\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2J3kgdVUaaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_mel_spect(spect):\n",
        "    # spect = spect.flatten()\n",
        "    # print(spect)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    librosa.display.specshow(spect.T, y_axis='mel', x_axis='time')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Test Melspectogram')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNABix_hQG6H",
        "colab_type": "code",
        "outputId": "58a5fcc1-0941-4de4-c004-83f55b655b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "\n",
        "# root_folder = \"/content/drive/My Drive/cs577- Deep learning/deepMusic/\"\n",
        "# AUDIO_DIR = root_folder + 'fma_small'\n",
        "\n",
        "# Read data\n",
        "tracks = pd.read_csv(config['tracks'], index_col=0)\n",
        "tracks = tracks[tracks.track_genre_top.isin(['Electronic', 'Folk', 'Rock','Hip-Hop'])]\n",
        "# ['Electronic', 'Folk', 'Rock']\n",
        "print(tracks['set_split'].shape)\n",
        "train = tracks.loc[tracks['set_split'] == 'training']\n",
        "val = tracks.loc[tracks['set_split'] == 'validation']\n",
        "test = tracks.loc[tracks['set_split'] == 'test']\n",
        "print(f'train -> {train.columns}')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13126,)\n",
            "train -> Index(['album_comments', 'album_date_created', 'album_date_released',\n",
            "       'album_engineer', 'album_favorites', 'album_id', 'album_information',\n",
            "       'album_listens', 'album_producer', 'album_tags', 'album_title',\n",
            "       'album_tracks', 'album_type', 'artist_active_year_begin',\n",
            "       'artist_active_year_end', 'artist_associated_labels', 'artist_bio',\n",
            "       'artist_comments', 'artist_date_created', 'artist_favorites',\n",
            "       'artist_id', 'artist_latitude', 'artist_location', 'artist_longitude',\n",
            "       'artist_members', 'artist_name', 'artist_related_projects',\n",
            "       'artist_tags', 'artist_website', 'artist_wikipedia_page', 'set_split',\n",
            "       'set_subset', 'track_bit_rate', 'track_comments', 'track_composer',\n",
            "       'track_date_created', 'track_date_recorded', 'track_duration',\n",
            "       'track_favorites', 'track_genre_top', 'track_genres',\n",
            "       'track_genres_all', 'track_information', 'track_interest',\n",
            "       'track_language_code', 'track_license', 'track_listens',\n",
            "       'track_lyricist', 'track_number', 'track_publisher', 'track_tags',\n",
            "       'track_title'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwiYWOcZRcxL",
        "colab_type": "code",
        "outputId": "d0a8d5c4-26b2-4724-b9e6-47209fd74d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "# Check which genres are present\n",
        "genres = list(LabelEncoder().fit(train['track_genre_top']).classes_)\n",
        "print('Top genres ({}): {}'.format(len(genres), genres))\n",
        "le = LabelEncoder()\n",
        "labels_encoded = np.asarray(le.fit_transform(tracks['track_genre_top']))\n",
        "labels_encoded = pd.DataFrame(labels_encoded, index=tracks.index)\n",
        "\n",
        "# print(f'label classes -> {le.classes_}')\n",
        "\n",
        "y_integers = labels_encoded.to_numpy().flatten()\n",
        "# print(f'labels_encoded -> {y_integers}')\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
        "d_class_weights = dict(enumerate(class_weights))\n",
        "# print(f'd_class_weights -> {d_class_weights}')\n",
        "\n",
        "# For local training purposes\n",
        "train = train.head(100)\n",
        "val = val.head(100)\n",
        "test = test.head(100)\n",
        "\n",
        "# print(f'train y -> {train[\"track_genre_top\"].unique()}')\n",
        "# print(f'val y -> {val[\"track_genre_top\"].unique()}')\n",
        "# print(f'test y -> {test[\"track_genre_top\"].unique()}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top genres (4): ['Electronic', 'Folk', 'Hip-Hop', 'Rock']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK1YRHb_POkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "IMPORTANT\n",
        "'''\n",
        "\n",
        "def compute_melgram(src, sr):\n",
        "    ''' Compute a mel-spectrogram and returns it in a shape of (1,1,96,1366), where\n",
        "    96 == #mel-bins and 1366 == #time frame\n",
        "\n",
        "    parameters\n",
        "    ----------\n",
        "    audio_path: path for the audio file.\n",
        "                Any format supported by audioread will work.\n",
        "    More info: http://librosa.github.io/librosa/generated/librosa.core.load.html#librosa.core.load\n",
        "\n",
        "    '''\n",
        "\n",
        "    # mel-spectrogram parameters\n",
        "    SR = 12000\n",
        "    N_FFT = 512\n",
        "    N_MELS = 96\n",
        "    HOP_LEN = 256\n",
        "    # DURA = 10\n",
        "    DURA = 29.12  # to make it 1366 frame..\n",
        "\n",
        "    # src, sr = librosa.load(audio_path, sr=SR)  # whole signal\n",
        "    n_sample = src.shape[0]\n",
        "    n_sample_fit = int(DURA*SR)\n",
        "    # print(f'n_sample_fit -> {n_sample_fit}')\n",
        "    # print(f'n_sample -> {n_sample}')\n",
        "    # print(src[int((n_sample-n_sample_fit)/2):int((n_sample+n_sample_fit)/2)])\n",
        "\n",
        "\n",
        "    if n_sample < n_sample_fit:  # if too short\n",
        "        src = np.hstack((src, np.zeros((int(DURA*SR) - n_sample,))))\n",
        "    elif n_sample > n_sample_fit:  # if too long\n",
        "        src = src[int((n_sample-n_sample_fit)/2):int((n_sample+n_sample_fit)/2)]\n",
        "    logam = librosa.amplitude_to_db\n",
        "    melgram = librosa.feature.melspectrogram\n",
        "    ret = logam(melgram(y=src, sr=SR, hop_length=HOP_LEN,\n",
        "                        n_fft=N_FFT, n_mels=N_MELS)**2,\n",
        "                ref=np.max)\n",
        "    # plot_mel_spect(ret)\n",
        "    ret = ret[np.newaxis, np.newaxis, :]\n",
        "    return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TUdItkeSTiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "IMPORTANT\n",
        "'''\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "\n",
        "    def __init__(self, list_IDs, labels, loader, audio_dir, batch_size=32, dim=(32, 32, 32), n_channels=1,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.loader = loader\n",
        "        self.audio_dir = audio_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        # print(list_IDs_temp)\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, self.n_channels, *self.dim))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # # Store sample\n",
        "            # signal, rate = self.loader.load(utils.get_audio_path(self.audio_dir, ID))\n",
        "            # sample = signal[:rate]\n",
        "            \n",
        "            # # Shorten the sample to 10 secs\n",
        "            # ran_index = np.random.randint(0, signal.shape[0] - int(rate / 10))\n",
        "            # sample = signal[ran_index:ran_index + int(rate / 10)]\n",
        "            # # print(f'shape of sample -> {sample.shape}')\n",
        "            # normalized_X = preprocessing.normalize(mfcc(sample, rate, numcep=13, nfilt=26, nfft=1103).T)\n",
        "            # temp = np.array(normalized_X)\n",
        "            # rshaped_X = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
        "            # X[i,] = rshaped_X\n",
        "\n",
        "            # Librosa version mel spectrogram\n",
        "            signal, sr = librosa.load(utils.get_audio_path(self.audio_dir, ID))\n",
        "            signal = signal.astype(float)\n",
        "            spect = compute_melgram(signal, sr)\n",
        "            X[i,] = spect\n",
        "            \n",
        "            # temp = np.array(spect)\n",
        "            # rshaped_X = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
        "            # X[i,] = rshaped_X\n",
        "            # X[i,] = np.array(spect)\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels.loc[ID].to_numpy()\n",
        "\n",
        "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PodcMiKf1MfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# METHOD 2 - DATAGENERATOR\n",
        "training_generator = DataGenerator(train.index.values, labels_encoded, config['audio_loader'], config['audio_dir'], **config['generator_params'])\n",
        "x , y  = training_generator.__getitem__(0)\n",
        "print(x.shape)\n",
        "# print(train.loc[ID]['track_genre_top'])\n",
        "print(y)\n",
        "# Plot mel spect for audio file with ID 2\n",
        "# plot_mel_spect(x[0],2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp7np9sznbD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def pop_layer(model):\n",
        "    if not model.outputs:\n",
        "        raise Exception('Sequential model cannot be popped: model is empty.')\n",
        "\n",
        "    model.layers.pop()\n",
        "    if not model.layers:\n",
        "        model.outputs = []\n",
        "        model.inbound_nodes = []\n",
        "        model.outbound_nodes = []\n",
        "    else:\n",
        "        model.layers[-1].outbound_nodes = []\n",
        "        model.outputs = [model.layers[-1].output]\n",
        "    model.built = False\n",
        "\n",
        "\n",
        "def MusicTaggerCRNN(weights='msd', input_tensor=None):\n",
        "    '''Instantiate the MusicTaggerCRNN architecture,\n",
        "    optionally loading weights pre-trained\n",
        "    on Million Song Dataset. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_dim_ordering=\"tf\"` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The dimension ordering\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "\n",
        "    For preparing mel-spectrogram input, see\n",
        "    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
        "    You will need to install [Librosa](http://librosa.github.io/librosa/)\n",
        "    to use it.\n",
        "\n",
        "    # Arguments\n",
        "        weights: one of `None` (random initialization)\n",
        "            or \"msd\" (pre-training on ImageNet).\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    '''\n",
        "\n",
        "    K.set_image_data_format('channels_first')\n",
        "    if weights not in {'msd', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `msd` '\n",
        "                         '(pre-training on Million Song Dataset).')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (1, 96, 1366)\n",
        "    else:\n",
        "        input_shape = (96, 1366, 1)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        melgram_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        melgram_input = layers.Input(shape=input_tensor)\n",
        "\n",
        "    # Determine input axis\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "        freq_axis = 2\n",
        "        time_axis = 3\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "        freq_axis = 1\n",
        "        time_axis = 2\n",
        "\n",
        "    # Input block\n",
        "    # x = layers.ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
        "    # x = layers.BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n",
        "\n",
        "    # Conv block 1\n",
        "    x = layers.Convolution2D(16,(2, 2), border_mode='same', name='conv1',activation= 'selu', trainable=True,kernel_initializer='lecun_normal')(melgram_input)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn1', trainable=True)(x)\n",
        "    # x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool1')(x)\n",
        "    x = layers.AlphaDropout(0.1, name='dropout1', trainable=True)(x)\n",
        "\n",
        "    # Conv block 2\n",
        "    x = layers.Convolution2D(32,(2, 2), border_mode='same', name='conv2',activation= 'selu', trainable=True,kernel_initializer='lecun_normal')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn2', trainable=True)(x)\n",
        "    # x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')(x)\n",
        "    x = layers.AlphaDropout(0.1, name='dropout2', trainable=True)(x)\n",
        "\n",
        "    # # Conv block 3\n",
        "    x = layers.Convolution2D(32,(3, 3), border_mode='same', name='conv3',activation= 'selu', trainable=True, kernel_initializer='lecun_normal')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=True)(x)\n",
        "    # x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool3')(x)\n",
        "    x = layers.AlphaDropout(0.1, name='dropout3', trainable=True)(x)\n",
        "    \n",
        "    # model = models.Model(melgram_input, x)\n",
        "    # model.summary()\n",
        "\n",
        "    # # Conv block 4\n",
        "    # x = layers.Convolution2D(16,( 4, 4), border_mode='same', name='conv4',activation= 'selu', trainable=True, kernel_initializer='lecun_normal')(x)\n",
        "    # x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn4', trainable=True)(x)\n",
        "    # # x = layers.ELU()(x)\n",
        "    # x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool4')(x)\n",
        "    # x = layers.Dropout(0.1, name='dropout4', trainable=True)(x)\n",
        "\n",
        "    # reshaping\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = layers.Permute((3, 1, 2))(x)\n",
        "    # print(f'permute size -> {x.shape}')\n",
        "    shape = x.get_shape().as_list()\n",
        "    x = layers.Reshape((shape[1]*shape[-1],shape[2]))(x)\n",
        "\n",
        "    # GRU block 1, 2, output\n",
        "    x = layers.GRU(8, return_sequences=True, name='gru1')(x)\n",
        "    x = layers.GRU(8, return_sequences=False, name='gru2')(x)\n",
        "    x = layers.AlphaDropout(0.3, name='final_drop')(x)\n",
        "\n",
        "    ## LSTM Layer\n",
        "    # layer = LSTM(96,return_sequences=False)(x)\n",
        "    # x = Dropout(0.4)(layer)\n",
        "    # print(f'lstm layer -> {layer.shape}')\n",
        "\n",
        "    if weights is None:\n",
        "        # x = layers.Flatten()(x)\n",
        "        x = layers.Dense(128, activation='relu', name='hidden1')(x)\n",
        "        x = layers.Dense(4, activation='softmax', name='output')(x)\n",
        "        print(f'x.shape -> {x.shape}')\n",
        "\n",
        "        model = models.Model(melgram_input, x)\n",
        "        # model.summary()\n",
        "        return model\n",
        "        # return x\n",
        "    else:\n",
        "        # Load input\n",
        "        x = layers.Dense(10, activation='sigmoid', name='output')(x)\n",
        "        if K.image_data_format() == 'channels_last':\n",
        "            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
        "                               \"You can set it at ~/.keras/keras.json\")\n",
        "        # Create model\n",
        "        initial_model = models.Model(melgram_input, x)\n",
        "        initial_model.load_weights('/content/crnn_net_gru_adam_ours_epoch_40.h5')\n",
        "\n",
        "        # Eliminate last layer\n",
        "        pop_layer(initial_model)\n",
        "        pop_layer(initial_model)\n",
        "        # Add new Dense layer\n",
        "        last = initial_model.get_layer('gru2')\n",
        "        preds = layers.Dense(4, activation='sigmoid', name='preds')(last.output)\n",
        "        model = models.Model(initial_model.input, preds)\n",
        "\n",
        "        # TO extend this model use this,\n",
        "        # model = Model(initial_model.input, initial_model.get_layer('dropout2').output)\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vs1X2R3d_E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_epocs_graph(history_dict,i):\n",
        "    loss_vals = history_dict['loss']\n",
        "    val_loss_vals = history_dict['val_loss']\n",
        "    epochs = range(1, len(history_dict['acc']) + 1)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss_vals, 'g', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss_vals, 'b', label='Validation Loss')\n",
        "    plt.title(\"Training and validation loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    acc_vals = history_dict['acc']\n",
        "    val_acc_vals = history_dict['val_acc']\n",
        "    plt.plot(epochs, acc_vals, 'g', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc_vals, 'b', label='Validation accuracy')\n",
        "    plt.title(\"Training and validation Accuracy\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(root_folder + f'graphs/log{i}.png')\n",
        "    plt.show()\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m_4ka4l0mYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network_config = {\n",
        "    'input_shape' : (1,96,1366),\n",
        "    # 'input_shape' : (1,96,469),\n",
        "    'loss' : 'categorical_crossentropy',\n",
        "    'optimizer' : optimizers.Adam(learning_rate=0.001),\n",
        "    'metrics' : ['acc'],\n",
        "    'epochs' : 10,\n",
        "    'batch_size':128,\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thaLUsaWSQBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn\n",
        "# model = gen_model()\n",
        "\n",
        "# CRNN\n",
        "# input_shape = (1,96,1366)\n",
        "# model_input = layers.Input(input_shape, name='input')\n",
        "# model = conv_recurrent_model_build(model_input,input_shape)\n",
        "\n",
        "# CNN by mdeff\n",
        "# input_shape = (1,96,704)\n",
        "# model = getMdeff_model(input_shape)\n",
        "\n",
        "# Another trial CRNN\n",
        "model = MusicTaggerCRNN(weights=None, input_tensor=network_config['input_shape'])\n",
        "\n",
        "model.compile(loss=network_config['loss'],\n",
        "              optimizer=network_config['optimizer'],\n",
        "              metrics=network_config['metrics'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(train.index.values, labels_encoded,config['audio_loader'],config['audio_dir'], **config['generator_params'])\n",
        "validation_generator = DataGenerator(val.index.values, labels_encoded,config['audio_loader'],config['audio_dir'], **config['generator_params'])\n",
        "test_generator = DataGenerator(test.index.values, labels_encoded,config['audio_loader'],config['audio_dir'], **config['generator_params'])\n",
        "\n",
        "# # Train model on dataset\n",
        "train_val_history = model.fit_generator(generator=training_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    class_weight = d_class_weights,\n",
        "                    epochs=network_config['epochs'],\n",
        "                    use_multiprocessing=True,\n",
        "                     workers=1)\n",
        "history_dict = train_val_history.history\n",
        "plot_epocs_graph(history_dict=history_dict)\n",
        "\n",
        "print(f'Testing...')\n",
        "test_op = model.evaluate_generator(generator = test_generator)\n",
        "print('Testing accuracy -> ',test_op)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVYnJESrR_j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# def gen_model():\n",
        "#   # Input shape is this because 13->numcep in mfcc function and 9 -> number of frames considered\n",
        "#   # input_shape = (13, 9, 1)\n",
        "#   input_shape = (64, 87, 1)\n",
        "\n",
        "#   # Network Architecture\n",
        "#   # tf.keras.backend.clear_session()\n",
        "\n",
        "#   model = models.Sequential()\n",
        "\n",
        "#   model.add(layers.Conv2D(16, (3, 3), activation='relu',\n",
        "#                           strides=(1, 1), padding='same',\n",
        "#                           input_shape=input_shape))\n",
        "#   model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "#                           strides=(1, 1), padding='same',\n",
        "#                           ))\n",
        "#   model.add(layers.MaxPool2D(2, 2))\n",
        "#   model.add(layers.Dropout(0.5))\n",
        "#   model.add(layers.Flatten())\n",
        "#   model.add(layers.Dense(128, activation='relu'))\n",
        "#   model.add(layers.Dense(64, activation='relu'))\n",
        "#   model.add(layers.Dense(8, activation='softmax'))\n",
        "#   model.summary()\n",
        "\n",
        "#   # optimizer = optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
        "#   optimizer = optimizers.Adam(lr=0.01)\n",
        "#   model.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "#   return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVRzvz45ZT0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This is to be used when using all the classes\n",
        "\n",
        "'''\n",
        "# def pop_layer(model):\n",
        "#     if not model.outputs:\n",
        "#         raise Exception('Sequential model cannot be popped: model is empty.')\n",
        "\n",
        "#     model.layers.pop()\n",
        "#     if not model.layers:\n",
        "#         model.outputs = []\n",
        "#         model.inbound_nodes = []\n",
        "#         model.outbound_nodes = []\n",
        "#     else:\n",
        "#         model.layers[-1].outbound_nodes = []\n",
        "#         model.outputs = [model.layers[-1].output]\n",
        "#     model.built = False\n",
        "\n",
        "\n",
        "# def MusicTaggerCRNN(weights='msd', input_tensor=None):\n",
        "#     '''Instantiate the MusicTaggerCRNN architecture,\n",
        "#     optionally loading weights pre-trained\n",
        "#     on Million Song Dataset. Note that when using TensorFlow,\n",
        "#     for best performance you should set\n",
        "#     `image_dim_ordering=\"tf\"` in your Keras config\n",
        "#     at ~/.keras/keras.json.\n",
        "\n",
        "#     The model and the weights are compatible with both\n",
        "#     TensorFlow and Theano. The dimension ordering\n",
        "#     convention used by the model is the one\n",
        "#     specified in your Keras config file.\n",
        "\n",
        "#     For preparing mel-spectrogram input, see\n",
        "#     `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
        "#     You will need to install [Librosa](http://librosa.github.io/librosa/)\n",
        "#     to use it.\n",
        "\n",
        "#     # Arguments\n",
        "#         weights: one of `None` (random initialization)\n",
        "#             or \"msd\" (pre-training on ImageNet).\n",
        "#         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "#             to use as image input for the model.\n",
        "#     # Returns\n",
        "#         A Keras model instance.\n",
        "#     '''\n",
        "\n",
        "#     K.set_image_data_format('channels_first')\n",
        "#     if weights not in {'msd', None}:\n",
        "#         raise ValueError('The `weights` argument should be either '\n",
        "#                          '`None` (random initialization) or `msd` '\n",
        "#                          '(pre-training on Million Song Dataset).')\n",
        "\n",
        "#     # Determine proper input shape\n",
        "#     if K.image_data_format() == 'channels_first':\n",
        "#         input_shape = (1, 96, 1366)\n",
        "#     else:\n",
        "#         input_shape = (96, 1366, 1)\n",
        "\n",
        "#     if input_tensor is None:\n",
        "#         melgram_input = layers.Input(shape=input_shape)\n",
        "#     else:\n",
        "#         melgram_input = layers.Input(shape=input_tensor)\n",
        "\n",
        "#     # Determine input axis\n",
        "#     if K.image_data_format() == 'channels_first':\n",
        "#         channel_axis = 1\n",
        "#         freq_axis = 2\n",
        "#         time_axis = 3\n",
        "#     else:\n",
        "#         channel_axis = 3\n",
        "#         freq_axis = 1\n",
        "#         time_axis = 2\n",
        "\n",
        "#     # Input block\n",
        "#     # x = layers.ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
        "#     # x = layers.BatchNormalization(axis=time_axis, name='bn_0_freq')(melgram_input)\n",
        "\n",
        "#     # Conv block 1\n",
        "#     x = layers.Convolution2D(64,(3, 3), border_mode='same', name='conv1', trainable=True)(melgram_input)\n",
        "#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(x)\n",
        "#     x = layers.ELU()(x)\n",
        "#     x = layers.Dropout(0.1, name='dropout1')(x)\n",
        "\n",
        "#     # # Conv block 2\n",
        "#     x = layers.Convolution2D(128,(3, 3), border_mode='same', name='conv2', trainable=True)(x)\n",
        "#     x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n",
        "#     x = layers.ReLU()(x)\n",
        "#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')(x)\n",
        "#     x = layers.Dropout(0.1, name='dropout2')(x)\n",
        "\n",
        "#     # # Conv block 3\n",
        "#     x = layers.Convolution2D(128,( 3, 3),dilation_rate=2, border_mode='same', name='conv3', trainable=True)(x)\n",
        "#     x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n",
        "#     x = layers.ReLU()(x)\n",
        "#     x = layers.MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool3')(x)\n",
        "#     x = layers.Dropout(0.1, name='dropout3')(x)\n",
        "#     # model = models.Model(melgram_input, x)\n",
        "#     # model.summary()\n",
        "#     # # Conv block 4\n",
        "#     x = layers.Convolution2D(128,( 3, 3), border_mode='same', name='conv4', trainable=True)(x)\n",
        "#     x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n",
        "#     x = layers.ReLU()(x)\n",
        "#     x = layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n",
        "#     x = layers.Dropout(0.1, name='dropout4')(x)\n",
        "\n",
        "#     # print(f'x size -> {x.shape}')\n",
        "#     # reshaping\n",
        "#     if K.image_data_format() == 'channels_first':\n",
        "#         x = layers.Permute((3, 1, 2))(x)\n",
        "#     # print(f'permute size -> {x.shape}')\n",
        "#     shape = x.get_shape().as_list()\n",
        "#     # print(f'shape  -> {(shape[0],shape[1]*shape[-1],shape[2])}')\n",
        "#     # x = layers.Reshape((15, 128))(x)\n",
        "#     x = layers.Reshape((shape[1]*shape[-1],shape[2]))(x)\n",
        "#     # print(f'shape x -> {x.shape}')\n",
        "\n",
        "#     # GRU block 1, 2, output\n",
        "#     x = layers.GRU(64, return_sequences=True, name='gru1')(x)\n",
        "#     x = layers.GRU(32, return_sequences=False, name='gru2')(x)\n",
        "#     x = layers.Dropout(0.3, name='final_drop')(x)\n",
        "\n",
        "#     ## LSTM Layer\n",
        "#     # layer = LSTM(96,return_sequences=False)(x)\n",
        "#     # x = Dropout(0.4)(layer)\n",
        "#     # print(f'lstm layer -> {layer.shape}')\n",
        "\n",
        "#     if weights is None:\n",
        "#         # x = layers.Flatten()(x)\n",
        "#         # x = Dense(512, activation='relu', name='hidden1')(x)\n",
        "#         x = layers.Dense(4, activation='sigmoid', name='output')(x)\n",
        "#         print(f'x.shape -> {x.shape}')\n",
        "\n",
        "#         model = models.Model(melgram_input, x)\n",
        "#         # model.summary()\n",
        "#         return model\n",
        "#         # return x\n",
        "#     else:\n",
        "#         # Load input\n",
        "#         x = Dense(10, activation='sigmoid', name='output')(x)\n",
        "#         if K.image_data_format() == 'channels_last':\n",
        "#             raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
        "#                                \"You can set it at ~/.keras/keras.json\")\n",
        "#         # Create model\n",
        "#         initial_model = models.Model(melgram_input, x)\n",
        "#         initial_model.load_weights('/content/crnn_net_gru_adam_ours_epoch_40.h5')\n",
        "\n",
        "#         # Add new Dense layer\n",
        "#         last = initial_model.get_layer('final_drop')\n",
        "#         last = layers.Flatten()(last.output)\n",
        "#         preds = layers.Dense(8, activation='softmax', name='preds')(last)\n",
        "#         model = models.Model(initial_model.input, preds)\n",
        "\n",
        "#         # TO extend this model use this,\n",
        "#         # model = Model(initial_model.input, initial_model.get_layer('dropout2').output)\n",
        "\n",
        "#         return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeXzQczAaELc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras import backend as K\n",
        "# from keras.layers import Input, Dense\n",
        "# from keras.models import Model\n",
        "# from keras.layers import Dense, Dropout, Reshape, Permute, Flatten\n",
        "# from keras.layers.convolutional import Convolution2D\n",
        "# from keras.layers.convolutional import MaxPooling2D, ZeroPadding2D\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "# from keras.layers.advanced_activations import ELU\n",
        "# from keras.layers.recurrent import GRU\n",
        "# from keras.utils.data_utils import get_file\n",
        "\n",
        "# def DeepMusicCRNN(input_layer=None):\n",
        "#     '''\n",
        "#     # Arguments\n",
        "#         weights: one of `None` (random initialization)\n",
        "#             or \"msd\" (pre-training on ImageNet).\n",
        "#         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "#             to use as image input for the model.\n",
        "#     # Returns\n",
        "#         A Keras model instance.\n",
        "#     '''\n",
        "\n",
        "#     K.set_image_data_format('channels_first')\n",
        "\n",
        "\n",
        "#     # Determine input axis\n",
        "#     if K.image_data_format() == 'channels_first':\n",
        "#         channel_axis = 1\n",
        "#         freq_axis = 2\n",
        "#         time_axis = 3\n",
        "#     else:\n",
        "#         channel_axis = 3\n",
        "#         freq_axis = 1\n",
        "#         time_axis = 2\n",
        "\n",
        "#     # input_x = Input(shape=input_tensor)\n",
        "#     # Input block\n",
        "#     # x = ZeroPadding2D(padding=(0, 37),input_shape = input_tensor)(input_x)\n",
        "#     x = BatchNormalization(axis=time_axis, name='bn_0b_freq')(input_layer)\n",
        "\n",
        "#     # # Conv block 1\n",
        "#     x = Convolution2D(256, 3, 3, border_mode='same', name='conv1b', trainable=True)(x)\n",
        "#     x = BatchNormalization(axis=channel_axis, mode=0, name='bn1b', trainable=True)(x)\n",
        "#     x = ELU()(x)\n",
        "#     x = MaxPooling2D(pool_size=(2, 2), strides=(3, 3), name='pool1b', trainable=True)(x)\n",
        "#     x = Dropout(0.1, name='dropout1b', trainable=True)(x)\n",
        "\n",
        "#     # # Conv block 2\n",
        "#     x = Convolution2D(256, 3, 3, border_mode='same', name='conv2a', trainable=True)(x)\n",
        "#     x = BatchNormalization(axis=channel_axis, mode=0, name='bn2a', trainable=True)(x)\n",
        "#     x = ELU()(x)\n",
        "#     x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2a', trainable=True)(x)\n",
        "#     x = Dropout(0.1, name='dropout2', trainable=True)(x)\n",
        "\n",
        "#     # # Conv block 3\n",
        "#     # x = Convolution2D(128, 3, 3, border_mode='same', name='conv3', trainable=False)(x)\n",
        "#     # x = BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=False)(x)\n",
        "#     # x = ELU()(x)\n",
        "#     # x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3', trainable=False)(x)\n",
        "#     # x = Dropout(0.1, name='dropout3', trainable=False)(x)\n",
        "\n",
        "#     # # Conv block 4\n",
        "#     # x = Convolution2D(128, 3, 3, border_mode='same', name='conv4', trainable=False)(x)\n",
        "#     # x = BatchNormalization(axis=channel_axis, mode=0, name='bn4', trainable=False)(x)\n",
        "#     # x = ELU()(x)\n",
        "#     # x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4', trainable=False)(x)\n",
        "#     # x = Dropout(0.1, name='dropout4', trainable=False)(x)\n",
        "\n",
        "#     # reshaping\n",
        "#     # if K.image_data_format() == 'channels_first':\n",
        "#     #     x = Permute((3, 1, 2))(x)\n",
        "#     # x = Reshape((15, 256))(x)\n",
        "\n",
        "#     # # # GRU block 1, 2, output\n",
        "#     # x = GRU(32, return_sequences=True, name='gru1')(x)\n",
        "#     # x = GRU(32, return_sequences=False, name='gru2')(x)\n",
        "#     # x = Dropout(0.3, name='final_drop')(x)\n",
        "\n",
        "#     # Create model\n",
        "#     x = Flatten()(x)\n",
        "#     x = Dense(16, activation='relu', name='hidden')(x)\n",
        "#     x = Dense(8, activation='softmax', name='output')(x)\n",
        "#     # model = Model(input_x, x)\n",
        "#     # print(x.shape)\n",
        "#     # # model.summary()\n",
        "#     # return model\n",
        "#     return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF58iBAAM5V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def getMdeff_model(input_shape):\n",
        "#   model = models.Sequential()\n",
        "#   # model.add(layers.Reshape((-1, 1), input_shape=input_shape))\n",
        "#   # print(model.output_shape)\n",
        "\n",
        "#   model.add(layers.Conv1D(128, 512, subsample_length=512,input_shape=input_shape))\n",
        "#   # print(model.output_shape)\n",
        "#   model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "#   model.add(layers.Conv1D(32, 8))\n",
        "#   # print(model.output_shape)\n",
        "#   model.add(layers.Activation(\"relu\"))\n",
        "#   model.add(layers.MaxPooling1D(4))\n",
        "\n",
        "#   model.add(layers.Conv1D(32, 8))\n",
        "#   # print(model.output_shape)\n",
        "#   model.add(layers.Activation(\"relu\"))\n",
        "#   model.add(layers.MaxPooling1D(4))\n",
        "\n",
        "#   # print(model.output_shape)\n",
        "#   #model.add(Dropout(0.25))\n",
        "#   model.add(layers.Flatten())\n",
        "#   print(model.output_shape)\n",
        "#   model.add(layers.Dense(100))\n",
        "#   model.add(layers.Activation(\"relu\"))\n",
        "#   # print(model.output_shape)\n",
        "#   model.add(layers.Dense(labels_onehot.shape[1]))\n",
        "#   model.add(layers.Activation(\"softmax\"))\n",
        "#   # print(model.output_shape)\n",
        "\n",
        "#   optimizer = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "#   #optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
        "#   model.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "#   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4HXlVcG2Lcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_classes = 8\n",
        "# N_LAYERS = 3\n",
        "# FILTER_LENGTH = 5\n",
        "# CONV_FILTER_COUNT = 56\n",
        "# BATCH_SIZE = 32\n",
        "# LSTM_COUNT = 96\n",
        "# EPOCH_COUNT = 70\n",
        "# NUM_HIDDEN = 64\n",
        "# L2_regularization = 0.001\n",
        "\n",
        "\n",
        "# def conv_recurrent_model_build(model_input,input_shape):\n",
        "#     print('Building model...')\n",
        "#     layer = model_input\n",
        "    \n",
        "#     ### 3 1D Convolution Layers\n",
        "#     for i in range(N_LAYERS):\n",
        "#         # give name to the layers\n",
        "#         layer = layers.Conv2D(\n",
        "#                 filters=CONV_FILTER_COUNT,\n",
        "#                 kernel_size=FILTER_LENGTH,\n",
        "#                 kernel_regularizer=regularizers.l2(L2_regularization),  # Tried 0.001\n",
        "#                 name='convolution_' + str(i + 1),\n",
        "#                 data_format='channels_last',\n",
        "#                 strides=1, padding='same',\n",
        "#                 input_shape = input_shape\n",
        "#             )(layer)\n",
        "#         layer = layers.BatchNormalization(momentum=0.9)(layer)\n",
        "#         layer = layers.Activation('relu')(layer)\n",
        "#         layer = layers.MaxPooling2D(pool_size=2,padding='same',\n",
        "#                 data_format='channels_last',)(layer)\n",
        "#         layer = layers.Dropout(0.4)(layer)\n",
        "    \n",
        "#     # ## LSTM Layer\n",
        "#     # layer = layers.LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
        "#     # layer = layers.Dropout(0.4)(layer)\n",
        "    \n",
        "#     # ## Dense Layer\n",
        "#     # layer = layers.Dense(NUM_HIDDEN, kernel_regularizer=regularizers.l2(L2_regularization), name='dense1')(layer)\n",
        "#     # layer = layers.Dropout(0.4)(layer)\n",
        "    \n",
        "#     # ## Softmax Output\n",
        "#     # layer = layers.Dense(num_classes)(layer)\n",
        "#     # layer = layers.Activation('softmax', name='output_realtime')(layer)\n",
        "\n",
        "#     model_output = layer\n",
        "#     model = models.Model(model_input, model_output)\n",
        "    \n",
        "    \n",
        "#     opt = optimizers.Adam(lr=0.001)\n",
        "#     model.compile(\n",
        "#             loss='categorical_crossentropy',\n",
        "#             optimizer=opt,\n",
        "#             metrics=['acc']\n",
        "#         )\n",
        "    \n",
        "#     print(model.summary())\n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJzHcClh11xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Test the network\n",
        "# print(\"Testing network on test set...\")\n",
        "# test_history = model.evaluate_generator(test_generator,use_multiprocessing=True, workers=1)\n",
        "\n",
        "# print(test_history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}