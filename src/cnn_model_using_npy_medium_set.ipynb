{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "cnn_model_using_npy.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "bKYM_pGyTWXe",
    "colab_type": "code",
    "outputId": "1d1e3eb0-7e8b-461d-c96c-15c1a16422a2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "!pip install python_speech_features\n",
    "!pip install python-dotenv \n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already satisfied: python_speech_features in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.12.0)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xnbYpwQmb9vl",
    "colab_type": "code",
    "outputId": "32e6b4a5-5209-4c0d-9128-2eab2fcef219",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "!pip install keras --upgrade"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already up-to-date: keras in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.3.1)\nRequirement already satisfied, skipping upgrade: six>=1.9.0 in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (1.13.0)\nRequirement already satisfied, skipping upgrade: pyyaml in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (5.3)\nRequirement already satisfied, skipping upgrade: scipy>=0.14 in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (1.4.1)\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (1.1.0)\nRequirement already satisfied, skipping upgrade: h5py in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (2.10.0)\nRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (1.0.8)\nRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\bisar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras) (1.18.0)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jcPEqN0nU5yc",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# !pip list librosa"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jnRPrBVPP2lj",
    "colab_type": "code",
    "outputId": "c0df3348-af71-4292-a860-557720e9f221",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from python_speech_features import mfcc\n",
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import activations\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/cs577- Deep learning/deepMusic/')\n",
    "from sources import utils\n",
    "from sklearn import preprocessing\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from math import floor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus\n",
    "\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-791c6b9f8fe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/cs577- Deep learning/deepMusic/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rkycMAkFYqAv",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "root_folder = \"D:\\Code\\Desktop\\IIT\\Courses\\Spring 2020\\Deep Learning\\FInal Project\\github_project\\music_analysis_fp\\\\\"\n",
    "subset_config = {\n",
    "    \"audio_dir\": \"fma_medium\",\n",
    "    \"subset\": \"medium\"\n",
    "}\n",
    "\n",
    "gen_params = {\n",
    "    'dim': (96, 1366),\n",
    "    # 'dim': (96, 469),\n",
    "    'batch_size': 10,\n",
    "    'n_classes': 4,\n",
    "    'n_channels': 1,\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "\n",
    "config = {\n",
    "    'audio_dir': root_folder + \"data/\" + subset_config['audio_dir'],\n",
    "    'tracks': root_folder + 'data/fma_metadata/cleaned_' + subset_config['subset'] + '.csv',\n",
    "    'generator_params': gen_params,\n",
    "    'audio_loader': utils.FfmpegLoader()\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3QGhVxKbXLqm",
    "colab_type": "code",
    "outputId": "a4e665ac-ae03-42d3-a940-88990e3b2bb6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load npy files\n",
    "x_train = np.load(root_folder + \"data/npy_files/\" + subset_config['subset'] + \"/x_train.npy\")\n",
    "y_train = np.load(root_folder + \"data/npy_files/\" + subset_config['subset'] + \"/y_train.npy\")\n",
    "\n",
    "x_val = (np.load(root_folder + \"data/npy_files/\" + subset_config['subset'] + \"/x_val.npy\"))\n",
    "y_val = (np.load(root_folder + \"data/npy_files/\" + subset_config['subset'] + \"/y_val.npy\"))\n",
    "\n",
    "x_test = (np.load(root_folder + \"data/npy_files/\" + subset_config['subset'] + \"/x_test.npy\"))\n",
    "y_test = (np.load(root_folder + \"data/npy_files/\" + subset_config['subset'] + \"/y_test.npy\"))\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0]*x_train.shape[1],x_train.shape[2],x_train.shape[3],x_train.shape[4]))\n",
    "x_val = x_val.reshape((x_val.shape[0]*x_val.shape[1],x_val.shape[2],x_val.shape[3],x_val.shape[4]))\n",
    "x_test = x_test.reshape((x_test.shape[0]*x_test.shape[1],x_test.shape[2],x_test.shape[3],x_test.shape[4]))\n",
    "\n",
    "y_train = y_train.reshape((y_train.shape[0]*y_train.shape[1],y_train.shape[2]))\n",
    "y_val = y_val.reshape((y_val.shape[0]*y_val.shape[1],y_val.shape[2]))\n",
    "y_test = y_test.reshape((y_test.shape[0]*y_test.shape[1],y_test.shape[2]))\n",
    "\n",
    "print(f'y_train -> {y_train.shape}')\n",
    "print(f'x_train -> {x_train.shape}')\n",
    "print(f'x_val -> {len(x_val)}')\n",
    "print(f'x_test -> {len(x_test)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t2J3kgdVUaaB",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def plot_mel_spect(spect):\n",
    "    # spect = spect.flatten()\n",
    "    # print(spect)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    librosa.display.specshow(spect.T, y_axis='mel', x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Test Melspectogram')\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f5D0VwyAabIO",
    "colab_type": "code",
    "outputId": "634e05ca-80b9-4ab7-c185-0c171ba48283",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "plot_mel_spect(x_train[0][0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8vs1X2R3d_E1",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def plot_epocs_graph(history_dict,i):\n",
    "    loss_vals = history_dict['loss']\n",
    "    val_loss_vals = history_dict['val_loss']\n",
    "    epochs = range(1, len(history_dict['acc']) + 1)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss_vals, 'g', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss_vals, 'b', label='Validation Loss')\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    acc_vals = history_dict['acc']\n",
    "    val_acc_vals = history_dict['val_acc']\n",
    "    plt.plot(epochs, acc_vals, 'g', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc_vals, 'b', label='Validation accuracy')\n",
    "    plt.title(\"Training and validation Accuracy\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(root_folder + f'graphs/log{i}.png')\n",
    "    plt.show()\n",
    "    return"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LorFXUYGmK92",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "'''\n",
    "USE THIS FOR MEDIUM DATASET\n",
    "'''\n",
    "\n",
    "def pop_layer(model):\n",
    "    if not model.outputs:\n",
    "        raise Exception('Sequential model cannot be popped: model is empty.')\n",
    "\n",
    "    model.layers.pop()\n",
    "    if not model.layers:\n",
    "        model.outputs = []\n",
    "        model.inbound_nodes = []\n",
    "        model.outbound_nodes = []\n",
    "    else:\n",
    "        model.layers[-1].outbound_nodes = []\n",
    "        model.outputs = [model.layers[-1].output]\n",
    "    model.built = False\n",
    "\n",
    "\n",
    "def MusicTaggerCRNN(weights='msd', input_tensor=None):\n",
    "    '''Instantiate the MusicTaggerCRNN architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on Million Song Dataset. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    For preparing mel-spectrogram input, see\n",
    "    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
    "    You will need to install [Librosa](http://librosa.github.io/librosa/)\n",
    "    to use it.\n",
    "\n",
    "    # Arguments\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"msd\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    K.clear_session()\n",
    "    K.set_image_data_format('channels_first')\n",
    "    if weights not in {'msd', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `msd` '\n",
    "                         '(pre-training on Million Song Dataset).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, 96, 1366)\n",
    "    else:\n",
    "        input_shape = (96, 1366, 1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        melgram_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        melgram_input = layers.Input(shape=input_tensor)\n",
    "\n",
    "    # Determine input axis\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        freq_axis = 2\n",
    "        time_axis = 3\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "        freq_axis = 1\n",
    "        time_axis = 2\n",
    "\n",
    "    # Input block\n",
    "    # x = layers.ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
    "    # x = layers.BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n",
    "\n",
    "    # Conv block 1\n",
    "    x = layers.Convolution2D(16,(2, 2), border_mode='same', name='conv1',activation= 'selu', trainable=True,kernel_initializer='lecun_normal')(melgram_input)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn1', trainable=True)(x)\n",
    "    # x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool1')(x)\n",
    "    x = layers.AlphaDropout(0.1, name='dropout1', trainable=True)(x)\n",
    "\n",
    "    # Conv block 2\n",
    "    x = layers.Convolution2D(32,(2, 2), border_mode='same', name='conv2',activation= 'selu', trainable=True,kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn2', trainable=True)(x)\n",
    "    # x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2')(x)\n",
    "    x = layers.AlphaDropout(0.1, name='dropout2', trainable=True)(x)\n",
    "\n",
    "    # # Conv block 3\n",
    "    x = layers.Convolution2D(32,(3, 3), border_mode='same', name='conv3',activation= 'selu', trainable=True, kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=True)(x)\n",
    "    # x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool3')(x)\n",
    "    x = layers.AlphaDropout(0.1, name='dropout3', trainable=True)(x)\n",
    "\n",
    "\n",
    "    # reshaping\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = layers.Permute((3, 1, 2))(x)\n",
    "    # print(f'permute size -> {x.shape}')\n",
    "    shape = x.get_shape().as_list()\n",
    "    x = layers.Reshape((shape[1]*shape[-1],shape[2]))(x)\n",
    "\n",
    "    # GRU block 1, 2, output\n",
    "    x = layers.GRU(8, return_sequences=True, name='gru1')(x)\n",
    "    x = layers.GRU(8, return_sequences=False, name='gru2')(x)\n",
    "    x = layers.AlphaDropout(0.3, name='final_drop')(x)\n",
    "\n",
    "    ## LSTM Layer\n",
    "    # layer = LSTM(96,return_sequences=False)(x)\n",
    "    # x = Dropout(0.4)(layer)\n",
    "    # print(f'lstm layer -> {layer.shape}')\n",
    "\n",
    "    if weights is None:\n",
    "        x = layers.Dense(128, activation='relu', name='hidden1')(x)\n",
    "        x = layers.Dense(4, activation='softmax', name='output')(x)\n",
    "        print(f'x.shape -> {x.shape}')\n",
    "\n",
    "        model = models.Model(melgram_input, x)\n",
    "        # model.summary()\n",
    "        return model\n",
    "        # return x\n",
    "    else:\n",
    "        # Load input\n",
    "        x = layers.Dense(10, activation='sigmoid', name='output')(x)\n",
    "        if K.image_data_format() == 'channels_last':\n",
    "            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
    "                               \"You can set it at ~/.keras/keras.json\")\n",
    "        # Create model\n",
    "        initial_model = models.Model(melgram_input, x)\n",
    "        initial_model.load_weights('/content/crnn_net_gru_adam_ours_epoch_40.h5')\n",
    "\n",
    "        # Eliminate last layer\n",
    "        pop_layer(initial_model)\n",
    "        pop_layer(initial_model)\n",
    "        # Add new Dense layer\n",
    "        last = initial_model.get_layer('gru2')\n",
    "        preds = layers.Dense(4, activation='sigmoid', name='preds')(last.output)\n",
    "        model = models.Model(initial_model.input, preds)\n",
    "\n",
    "        # TO extend this model use this,\n",
    "        # model = Model(initial_model.input, initial_model.get_layer('dropout2').output)\n",
    "\n",
    "        return model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gIlwabedesd4",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "network_config = {\n",
    "    'input_shape' : (1,96,1366),\n",
    "    # 'input_shape' : (1,96,469),\n",
    "    'loss' : 'categorical_crossentropy',\n",
    "    'optimizer' : optimizers.Adam(learning_rate=0.0001),\n",
    "    'metrics' : ['acc'],\n",
    "    'epochs' : 20,\n",
    "    'batch_size':128,\n",
    "\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "thaLUsaWSQBb",
    "colab_type": "code",
    "outputId": "8899e71c-e391-4495-ac2f-4ab05d83cfdb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "model = MusicTaggerCRNN(weights=None, input_tensor=network_config['input_shape'])\n",
    "\n",
    "model.compile(loss=network_config['loss'],\n",
    "              optimizer=network_config['optimizer'],\n",
    "              metrics=network_config['metrics'])\n",
    "model.summary()\n",
    "\n",
    "# Training from memory\n",
    "train_val_history = model.fit(x_train,y_train,\n",
    "                              batch_size=network_config['batch_size'],\n",
    "                              epochs=network_config['epochs'],\n",
    "                              validation_data = (x_val, y_val))\n",
    "history_dict = train_val_history.history\n",
    "plot_epocs_graph(history_dict=history_dict,i=17)\n",
    "# model.save(root_folder + 'models/crnn_20.h5')\n",
    "\n",
    "print(f'Testing...')\n",
    "test_op = model.evaluate(x_test,y_test)\n",
    "print('Testing accuracy -> ',test_op)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LsTF_oZSlZ4v",
    "colab_type": "code",
    "outputId": "b7711d6e-081c-4fe3-f5f3-ea48542ddc85",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 933
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "weights_path = root_folder + 'models/crnn_20.h5'\n",
    "model = load_model(weights_path)\n",
    "x_test = (np.load(root_folder + \"npy_files_new/medium/medium/x_test.npy\"))\n",
    "y_test = (np.load(root_folder + \"npy_files_new/medium/medium/y_test.npy\"))\n",
    "y_test = y_test.reshape((y_test.shape[0]*y_test.shape[1],y_test.shape[2]))\n",
    "x_test = x_test.reshape((x_test.shape[0]*x_test.shape[1],x_test.shape[2],x_test.shape[3],x_test.shape[4]))\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(x_test, batch_size = 128)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred.shape)\n",
    "y_test_clasess = np.argmax(y_test, axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test_clasess, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in ['Electronic', 'Folk', 'Rock','Hip-Hop']],\n",
    "                  columns = [i for i in ['Electronic', 'Folk', 'Rock','Hip-Hop']])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "print('Classification Report')\n",
    "target_names = ['Electronic', 'Folk', 'Rock','Hip-Hop']\n",
    "print(classification_report(y_test_clasess, y_pred, target_names=target_names))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hXIoDMIzH1ph",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "'''\n",
    "USE IT FOR FMA SMALL DATASET\n",
    "\n",
    "'''\n",
    "# def pop_layer(model):\n",
    "#     if not model.outputs:\n",
    "#         raise Exception('Sequential model cannot be popped: model is empty.')\n",
    "\n",
    "#     model.layers.pop()\n",
    "#     if not model.layers:\n",
    "#         model.outputs = []\n",
    "#         model.inbound_nodes = []\n",
    "#         model.outbound_nodes = []\n",
    "#     else:\n",
    "#         model.layers[-1].outbound_nodes = []\n",
    "#         model.outputs = [model.layers[-1].output]\n",
    "#     model.built = False\n",
    "\n",
    "\n",
    "# def MusicTaggerCRNN(weights='msd', input_tensor=None):\n",
    "#     '''Instantiate the MusicTaggerCRNN architecture,\n",
    "#     optionally loading weights pre-trained\n",
    "#     on Million Song Dataset. Note that when using TensorFlow,\n",
    "#     for best performance you should set\n",
    "#     `image_dim_ordering=\"tf\"` in your Keras config\n",
    "#     at ~/.keras/keras.json.\n",
    "\n",
    "#     The model and the weights are compatible with both\n",
    "#     TensorFlow and Theano. The dimension ordering\n",
    "#     convention used by the model is the one\n",
    "#     specified in your Keras config file.\n",
    "\n",
    "#     For preparing mel-spectrogram input, see\n",
    "#     `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
    "#     You will need to install [Librosa](http://librosa.github.io/librosa/)\n",
    "#     to use it.\n",
    "\n",
    "#     # Arguments\n",
    "#         weights: one of `None` (random initialization)\n",
    "#             or \"msd\" (pre-training on ImageNet).\n",
    "#         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "#             to use as image input for the model.\n",
    "#     # Returns\n",
    "#         A Keras model instance.\n",
    "#     '''\n",
    "\n",
    "#     K.set_image_data_format('channels_first')\n",
    "#     if weights not in {'msd', None}:\n",
    "#         raise ValueError('The `weights` argument should be either '\n",
    "#                          '`None` (random initialization) or `msd` '\n",
    "#                          '(pre-training on Million Song Dataset).')\n",
    "\n",
    "#     # Determine proper input shape\n",
    "#     if K.image_data_format() == 'channels_first':\n",
    "#         input_shape = (1, 96, 1366)\n",
    "#     else:\n",
    "#         input_shape = (96, 1366, 1)\n",
    "\n",
    "#     if input_tensor is None:\n",
    "#         melgram_input = layers.Input(shape=input_shape)\n",
    "#     else:\n",
    "#         melgram_input = layers.Input(shape=input_tensor)\n",
    "\n",
    "#     # Determine input axis\n",
    "#     if K.image_data_format() == 'channels_first':\n",
    "#         channel_axis = 1\n",
    "#         freq_axis = 2\n",
    "#         time_axis = 3\n",
    "#     else:\n",
    "#         channel_axis = 3\n",
    "#         freq_axis = 1\n",
    "#         time_axis = 2\n",
    "\n",
    "#     # Input block\n",
    "#     # x = layers.ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
    "#     # x = layers.BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n",
    "\n",
    "#     # Conv block 1\n",
    "#     x = layers.Convolution2D(16,(2, 2), border_mode='same', name='conv1',activation= 'selu', trainable=True,kernel_initializer='lecun_normal')(melgram_input)\n",
    "#     x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn1', trainable=True)(x)\n",
    "#     # x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool1')(x)\n",
    "#     x = layers.AlphaDropout(0.1, name='dropout1', trainable=True)(x)\n",
    "\n",
    "#     # Conv block 2\n",
    "#     x = layers.Convolution2D(32,(2, 2), border_mode='same', name='conv2',activation= 'selu', trainable=True,kernel_initializer='lecun_normal')(x)\n",
    "#     x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn2', trainable=True)(x)\n",
    "#     # x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')(x)\n",
    "#     x = layers.AlphaDropout(0.1, name='dropout2', trainable=True)(x)\n",
    "\n",
    "#     # # Conv block 3\n",
    "#     x = layers.Convolution2D(32,(3, 3), border_mode='same', name='conv3',activation= 'selu', trainable=True, kernel_initializer='lecun_normal')(x)\n",
    "#     x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=True)(x)\n",
    "#     # x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool3')(x)\n",
    "#     x = layers.AlphaDropout(0.1, name='dropout3', trainable=True)(x)\n",
    "    \n",
    "#     # model = models.Model(melgram_input, x)\n",
    "#     # model.summary()\n",
    "\n",
    "#     # # Conv block 4\n",
    "#     # x = layers.Convolution2D(16,( 4, 4), border_mode='same', name='conv4',activation= 'selu', trainable=True, kernel_initializer='lecun_normal')(x)\n",
    "#     # x = layers.BatchNormalization(axis=channel_axis, mode=0, name='bn4', trainable=True)(x)\n",
    "#     # # x = layers.ELU()(x)\n",
    "#     # x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool4')(x)\n",
    "#     # x = layers.Dropout(0.1, name='dropout4', trainable=True)(x)\n",
    "\n",
    "#     # reshaping\n",
    "#     if K.image_data_format() == 'channels_first':\n",
    "#         x = layers.Permute((3, 1, 2))(x)\n",
    "#     # print(f'permute size -> {x.shape}')\n",
    "#     shape = x.get_shape().as_list()\n",
    "#     x = layers.Reshape((shape[1]*shape[-1],shape[2]))(x)\n",
    "\n",
    "#     # GRU block 1, 2, output\n",
    "#     x = layers.GRU(8, return_sequences=True, name='gru1')(x)\n",
    "#     x = layers.GRU(8, return_sequences=False, name='gru2')(x)\n",
    "#     x = layers.AlphaDropout(0.3, name='final_drop')(x)\n",
    "\n",
    "#     ## LSTM Layer\n",
    "#     # layer = LSTM(96,return_sequences=False)(x)\n",
    "#     # x = Dropout(0.4)(layer)\n",
    "#     # print(f'lstm layer -> {layer.shape}')\n",
    "\n",
    "#     if weights is None:\n",
    "#         # x = layers.Flatten()(x)\n",
    "#         x = layers.Dense(128, activation='relu', name='hidden1')(x)\n",
    "#         x = layers.Dense(4, activation='softmax', name='output')(x)\n",
    "#         print(f'x.shape -> {x.shape}')\n",
    "\n",
    "#         model = models.Model(melgram_input, x)\n",
    "#         # model.summary()\n",
    "#         return model\n",
    "#         # return x\n",
    "#     else:\n",
    "#         # Load input\n",
    "#         x = layers.Dense(10, activation='sigmoid', name='output')(x)\n",
    "#         if K.image_data_format() == 'channels_last':\n",
    "#             raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
    "#                                \"You can set it at ~/.keras/keras.json\")\n",
    "#         # Create model\n",
    "#         initial_model = models.Model(melgram_input, x)\n",
    "#         initial_model.load_weights('/content/crnn_net_gru_adam_ours_epoch_40.h5')\n",
    "\n",
    "#         # Eliminate last layer\n",
    "#         pop_layer(initial_model)\n",
    "#         pop_layer(initial_model)\n",
    "#         # Add new Dense layer\n",
    "#         last = initial_model.get_layer('gru2')\n",
    "#         preds = layers.Dense(4, activation='sigmoid', name='preds')(last.output)\n",
    "#         model = models.Model(initial_model.input, preds)\n",
    "\n",
    "#         # TO extend this model use this,\n",
    "#         # model = Model(initial_model.input, initial_model.get_layer('dropout2').output)\n",
    "\n",
    "#         return model"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}